const std = @import("std");
const ArrayList = std.ArrayList;
const json = std.json;
const StringPool = @import("stringpool.zig").StringPool;
const path_sep = std.fs.path.sep_str;

var arena = std.heap.ArenaAllocator.init(std.heap.page_allocator);
const allocator = &arena.allocator;

const autogen_header = "//! NOTE: this file is autogenerated, DO NOT MODIFY\n";

var global_void_type_from_pool_ptr : [*]const u8 = undefined;
var global_symbol_pool = StringPool.init(allocator);
var global_type_map = StringPool.HashMap(TypeEntry).init(allocator);

const NativeType = enum {
    Boolean,
    SByte,
    Byte,
    Int16,
    UInt16,
    Int32,
    UInt32,
    Int64,
    UInt64,
    Single,
    Double,
    String,
    IntPtr,
    UIntPtr,
    Guid,
};
const global_native_type_map = std.ComptimeStringMap(NativeType, .{
    .{ "Boolean", NativeType.Boolean },
    .{ "SByte", NativeType.SByte },
    .{ "Byte", NativeType.Byte },
    .{ "Int16", NativeType.Int16 },
    .{ "UInt16", NativeType.UInt16 },
    .{ "Int32", NativeType.Int32 },
    .{ "UInt32", NativeType.UInt32 },
    .{ "Int64", NativeType.Int64 },
    .{ "UInt64", NativeType.UInt64 },
    .{ "Single", NativeType.Single },
    .{ "Double", NativeType.Double },
    .{ "String", NativeType.String },
    .{ "IntPtr", NativeType.IntPtr },
    .{ "UIntPtr", NativeType.UIntPtr },
    .{ "Guid", NativeType.Guid },
});
fn nativeTypeToZigType(t: NativeType) []const u8 {
    return switch (t) {
        .Boolean => return "bool",
        .SByte => return "i8",
        .Byte => return "u8",
        .Int16 => return "i16",
        .UInt16 => return "u16",
        .Int32 => return "i32",
        .UInt32 => return "u32",
        .Int64 => return "i64",
        .UInt64 => return "u64",
        .Single => return "f32",
        .Double => return "f64",
        .String => return "[]const u8",
        .IntPtr => return "?*opaque{}",
        .UIntPtr => return "?*opaque{}",
        .Guid => @panic("cannot call nativeTypeToZigType for NativeType.Guid"),
    };
}

const Nothing = struct {};

const SdkFile = struct {
    json_basename2: []const u8,
    name_original_case: []const u8,
    name_snake_case: []const u8,
    zig_filename: []const u8,
    const_exports: ArrayList(StringPool.Val),
    uses_guid: bool,
    top_level_api_imports: StringPool.HashMap(StringPool.Val),
    type_exports: StringPool.HashMap(Nothing),
    func_exports: StringPool.HashMap(Nothing),

    pub fn create(json_basename: []const u8) !*SdkFile {
        const sdk_file = try allocator.create(SdkFile);
        errdefer allocator.destroy(sdk_file);
        const name_original_case = json_basename[0..json_basename.len - ".json".len];
        const name_snake_case = try camelToSnake(allocator, name_original_case);
        errdefer allocator.free(name_snake_case);
        const zig_filename = try std.mem.concat(allocator, u8, &[_][]const u8 {name_snake_case, ".zig"});
        errdefer allocator.free(zig_filename);

        sdk_file.* = .{
            .json_basename2 = json_basename,
            .name_original_case = name_original_case,
            .name_snake_case = name_snake_case,
            .zig_filename = zig_filename,
            .const_exports = ArrayList(StringPool.Val).init(allocator),
            .uses_guid = false,
            .top_level_api_imports = StringPool.HashMap(StringPool.Val).init(allocator),
            .type_exports = StringPool.HashMap(Nothing).init(allocator),
            .func_exports = StringPool.HashMap(Nothing).init(allocator),
        };
        return sdk_file;
    }

    pub fn addApiImport(self: *SdkFile, name: []const u8, api: []const u8, parents: json.Array) !void {
        if (!std.mem.eql(u8, self.name_original_case, api)) {
            const top_level_symbol = try global_symbol_pool.add(
                if (parents.items.len == 0) name else parents.items[0].String);
            const pool_api = try global_symbol_pool.add(api);
            if (self.top_level_api_imports.get(top_level_symbol)) |other_api| {
                jsonEnforceMsg(pool_api.eql(other_api), "symbol conflict '{s}', api mismatch '{s}' and '{s}'", .{name, pool_api, other_api});
                //jsonEnforceMsg(other.parents.len == 0, "symbol conflict '{s}', parents mismatch", .{name});
            } else {
                try self.top_level_api_imports.put(top_level_symbol, pool_api);
            }
        }
    }
};

const SharedTypeExportEntry = struct {
    first_sdk_file_ptr: *SdkFile,
    duplicates: u32,
};

const Times = struct {
    parse_time_millis : i64 = 0,
    read_time_millis : i64 = 0,
    generate_time_millis : i64 = 0,
};
var global_times = Times {};

pub fn main() !u8 {
    return main2() catch |e| switch (e) {
        error.AlreadyReported => return 0xff,
        else => return e,
    };
}
fn main2() !u8 {
    const main_start_millis = std.time.milliTimestamp();
    var print_time_summary = false;
    defer {
        if (print_time_summary) {
            var total_millis = std.time.milliTimestamp() - main_start_millis;
            if (total_millis == 0) total_millis = 1; // prevent divide by 0
            std.debug.warn("Parse Time: {} millis ({}%)\n", .{global_times.parse_time_millis, @divTrunc(100 * global_times.parse_time_millis, total_millis)});
            std.debug.warn("Read Time : {} millis ({}%)\n", .{global_times.read_time_millis , @divTrunc(100 * global_times.read_time_millis, total_millis)});
            std.debug.warn("Gen Time  : {} millis ({}%)\n", .{global_times.generate_time_millis , @divTrunc(100 * global_times.generate_time_millis, total_millis)});
            std.debug.warn("Total Time: {} millis\n", .{total_millis});
        }
    }

    const win32json_dir_name = "deps" ++ path_sep ++ "win32json";
    // TODO: change this to a SHA!!!
    const win32json_checkout = "main";
    var win32json_dir = std.fs.cwd().openDir(win32json_dir_name, .{}) catch |e| switch (e) {
        error.FileNotFound => {
            std.debug.warn("Error: repository '{s}' does not exist, clone it with:\n", .{win32json_dir_name});
            std.debug.warn("    git clone https://github.com/marlersoft/win32json {0s}" ++ path_sep ++ win32json_dir_name
                ++ " && git -C {0s}" ++ path_sep ++ win32json_dir_name ++ " checkout " ++ win32json_checkout ++ " -b release\n", .{
                    try getcwd(allocator)
            });
            return error.AlreadyReported;
        },
        else => return e,
    };
    defer win32json_dir.close();

    var api_dir = try win32json_dir.openDir("api", .{.iterate = true}) ;
    defer api_dir.close();

    const cwd = std.fs.cwd();

    const zigwin32_dir_name = "zigwin32";
    cwd.access(zigwin32_dir_name, .{}) catch |e| switch (e) {
        error.FileNotFound => {
            std.debug.warn("Error: repository '{s}' does not exist, clone it with:\n", .{zigwin32_dir_name});
            std.debug.warn("    git clone https://github.com/marlersoft/zigwin32 {s}" ++ path_sep ++ zigwin32_dir_name ++ "\n", .{
                try getcwd(allocator)
            });
            return error.AlreadyReported;
        },
        else => return e,
    };

    const out_dir_string = zigwin32_dir_name ++ path_sep ++ "src";
    try cleanDir(cwd, out_dir_string);
    var out_dir = try cwd.openDir(out_dir_string, .{});
    defer out_dir.close();

    try out_dir.makeDir("win32");
    var out_win32_dir = try out_dir.openDir("win32", .{});
    defer out_win32_dir.close();

    // copy zig.zig module
    {
        var src_dir = try cwd.openDir("src", .{});
        defer src_dir.close();
        try src_dir.copyFile("zig.zig", out_win32_dir, "zig.zig", .{});
    }

    var shared_type_export_map = StringPool.HashMap(SharedTypeExportEntry).init(allocator);
    defer shared_type_export_map.deinit();

    var sdk_files = ArrayList(*SdkFile).init(allocator);
    defer sdk_files.deinit();
    {
        try out_win32_dir.makeDir("api");
        var out_api_dir = try out_win32_dir.openDir("api", .{});
        defer out_api_dir.close();

        std.debug.warn("-----------------------------------------------------------------------\n", .{});
        std.debug.warn("loading api json files...\n", .{});
        var dir_it = api_dir.iterate();
        while (try dir_it.next()) |entry| {
            if (!std.mem.endsWith(u8, entry.name, ".json")) {
                std.debug.warn("Error: expected all files to end in '.json' but got '{s}'\n", .{entry.name});
                return error.AlreadyReported;
            }
            if (std.mem.eql(u8, entry.name, "Js.json2")) {
                std.debug.warn("NOTE: skipping '{s}' because it has an integer that is too big: https://github.com/ziglang/zig/issues/7901\n", .{entry.name});
                continue;
            }
            std.debug.warn("loading '{s}'\n", .{entry.name});
            //
            // TODO: would things run faster if I just memory mapped the file?
            //
            var file = try api_dir.openFile(entry.name, .{});
            defer file.close();
            try readAndGenerateApiFile(out_api_dir, &sdk_files, entry.name, file);
        }

        // populate the shared_type_export_map
        for (sdk_files.items) |sdk_file| {
            var type_export_it = sdk_file.type_exports.iterator();
            while (type_export_it.next()) |kv| {
                const type_name = kv.key;
                if (shared_type_export_map.get(type_name)) |entry| {
                    // handle duplicates symbols (https://github.com/ohjeongwook/windows_sdk_data/issues/2)
                    // TODO: uncomment this warning after all types start being generated
                    // For now, a warning about this will be included in the generated everything.zig file below
                    //std.debug.warn("WARNING: type '{s}' in '{s}' conflicts with type in '{s}'\n", .{
                    //    type_name, sdk_file.name, entry.first_sdk_file_ptr.name});
                    try shared_type_export_map.put(type_name, .{ .first_sdk_file_ptr = entry.first_sdk_file_ptr, .duplicates = entry.duplicates + 1 });
                } else {
                    try shared_type_export_map.put(type_name, .{ .first_sdk_file_ptr = sdk_file, .duplicates = 0 });
                }
            }
        }

        {
            var api_file = try out_win32_dir.createFile("api.zig", .{});
            defer api_file.close();
            const writer = api_file.writer();
            try writer.writeAll(autogen_header);
            for (sdk_files.items) |sdk_file| {
                try writer.print("pub const {s} = @import(\"api/{0s}.zig\");\n", .{sdk_file.name_snake_case});
            }
            try writer.writeAll(
                \\test "" {
                \\
            );
            try writer.print("    const api_count = {};\n", .{sdk_files.items.len});
            try writer.writeAll(
                \\    @setEvalBranchQuota(api_count);
                \\    @import("std").testing.refAllDecls(@This());
                \\}
                \\
            );
        }

        {
            var everything_file = try out_win32_dir.createFile("everything.zig", .{});
            defer everything_file.close();
            const writer = everything_file.writer();
            try writer.writeAll(autogen_header ++
                \\//! This module contains aliases to ALL symbols inside the Win32 SDK.  It allows
                \\//! an application to access any and all symbols through a single import.
                \\
                \\pub const L = @import("zig.zig").L;
                \\
            );

            // TODO: workaround issue where constants/functions are defined more than once, not sure what the right solution
            //       is for all these, maybe some modules are not compatible with each other.  This could just be the permanent
            //       solution as well, if there are conflicts, we could just say the user has to import the specific module they want.
            var shared_const_map = StringPool.HashMap(*SdkFile).init(allocator);
            defer shared_const_map.deinit();
            var shared_func_map = StringPool.HashMap(*SdkFile).init(allocator);
            defer shared_func_map.deinit();

            // we wrap all the api symbols in a sub-struct because some of the api
            // names conflict some of the symbols.  This prevents those conflicts.
            try writer.print("const api = struct {{\n", .{});
            for (sdk_files.items) |sdk_file| {
                try writer.print("    const {s} = @import(\"api/{0s}.zig\");\n", .{sdk_file.name_snake_case});
            }
            try writer.print("}};\n", .{});
            for (sdk_files.items) |sdk_file| {
                try writer.print("// {s} exports {} constants:\n", .{sdk_file.name_snake_case, sdk_file.const_exports.items.len});
                for (sdk_file.const_exports.items) |constant| {
                    if (shared_const_map.get(constant)) |other_sdk_file| {
                        try writer.print("// WARNING: redifinition of constant '{s}' in module '{s}' (going with module '{s}')\n", .{
                            constant, sdk_file.name_snake_case, other_sdk_file.name_snake_case});
                    } else {
                        try writer.print("pub const {s} = api.{s}.{0s};\n", .{constant, sdk_file.name_snake_case});
                        try shared_const_map.put(constant, sdk_file);
                    }
                }
                try writer.print("// {s} exports {} types:\n", .{sdk_file.name_snake_case, sdk_file.type_exports.count()});
                var export_it = sdk_file.type_exports.iterator();
                while (export_it.next()) |kv| {
                    const type_name = kv.key;
                    const type_entry = shared_type_export_map.get(type_name) orelse unreachable;
                    if (type_entry.first_sdk_file_ptr != sdk_file) {
                        try writer.print("// WARNING: type '{s}.{s}' has {} definitions, going with '{s}'\n", .{
                            sdk_file.name_snake_case, type_name, type_entry.duplicates + 1, type_entry.first_sdk_file_ptr.name_snake_case});
                    } else {
                        try writer.print("pub const {s} = api.{s}.{0s};\n", .{type_name, sdk_file.name_snake_case});
                    }
                }
                try writer.print("// {s} exports {} functions:\n", .{sdk_file.name_snake_case, sdk_file.func_exports.count()});
                var func_it = sdk_file.func_exports.iterator();
                while (func_it.next()) |kv| {
                    const func = kv.key;
                    if (shared_func_map.get(func)) |other_sdk_file| {
                        try writer.print("// WARNING: redifinition of function '{s}' in module '{s}' (going with module '{s}')\n", .{
                            func, sdk_file.name_snake_case, other_sdk_file.name_snake_case});
                    } else {
                        try writer.print("pub const {s} = api.{s}.{0s};\n", .{func, sdk_file.name_snake_case});
                        try shared_func_map.put(func, sdk_file);
                    }
                }
            }
        }
    }

    {
        var win32_file = try out_dir.createFile("win32.zig", .{});
        defer win32_file.close();
        const writer = win32_file.writer();
        try writer.writeAll(autogen_header ++
            \\pub const api = @import("win32/api.zig");
            \\pub const zig = @import("win32/zig.zig");
            \\pub const everything = @import("win32/everything.zig");
            \\
            \\const std = @import("std");
            \\test "" {
            \\    std.testing.refAllDecls(@This());
            \\}
            \\
        );
    }
    print_time_summary = true;
    return 0;
}

fn readAndGenerateApiFile(out_dir: std.fs.Dir, sdk_files: *ArrayList(*SdkFile), json_basename: []const u8, file: std.fs.File) !void {

    const read_start_millis = std.time.milliTimestamp();
    const content = try file.readToEndAlloc(allocator, std.math.maxInt(usize));
    global_times.read_time_millis += std.time.milliTimestamp() - read_start_millis;
    defer allocator.free(content);
    std.debug.warn("  read {} bytes\n", .{content.len});

    // Parsing the JSON is VERY VERY SLOW!!!!!!
    var parser = json.Parser.init(allocator, false); // false is copy_strings
    defer parser.deinit();
    const parse_start_millis = std.time.milliTimestamp();

    const start = if (std.mem.startsWith(u8, content, "\xEF\xBB\xBF")) 3 else @as(usize, 0);
    const json_content = content[start..];
    var json_tree = try parser.parse(json_content);
    defer json_tree.deinit();
    global_times.parse_time_millis += std.time.milliTimestamp() - parse_start_millis;

    var sdk_file = try SdkFile.create(try std.mem.dupe(allocator, u8, json_basename));
    try sdk_files.append(sdk_file);
    const generate_start_millis = std.time.milliTimestamp();
    try generateFile(out_dir, sdk_file, json_tree);
    global_times.generate_time_millis += std.time.milliTimestamp() - generate_start_millis;
}

fn generateFile(out_dir: std.fs.Dir, sdk_file: *SdkFile, tree: json.ValueTree) !void {
    var out_file = try out_dir.createFile(sdk_file.zig_filename, .{});
    defer out_file.close();
    const out_writer = out_file.writer();

    try out_writer.writeAll(autogen_header);
    // We can't import the everything module because it will re-introduce the same symbols we are exporting
    //try out_writer.print("usingnamespace @import(\"everything.zig\");\n", .{});
    const root_obj = tree.root.Object;
    const constants_array = (try jsonObjGetRequired(root_obj, "Constants", sdk_file)).Array;
    const types_array = (try jsonObjGetRequired(root_obj, "Types", sdk_file)).Array;
    const functions_array = (try jsonObjGetRequired(root_obj, "Functions", sdk_file)).Array;
    const unicode_aliases = (try jsonObjGetRequired(root_obj, "UnicodeAliases", sdk_file)).Array;
    try out_writer.print("//\n", .{});
    try out_writer.print("// {} Constants\n", .{constants_array.items.len});
    try out_writer.print("//\n", .{});
    for (constants_array.items) |constant_node| {
        try generateConstant(sdk_file, out_writer, constant_node.Object);
    }
    std.debug.assert(constants_array.items.len == sdk_file.const_exports.items.len);
    try out_writer.print("\n", .{});
    try out_writer.print("//\n", .{});
    try out_writer.print("// {} Types\n", .{types_array.items.len});
    try out_writer.print("//\n", .{});
    for (types_array.items) |type_node| {
        try generateType(sdk_file, out_writer, type_node.Object);
    }
    std.debug.assert(types_array.items.len == sdk_file.type_exports.count());
    try out_writer.print("\n", .{});
    try out_writer.print("//\n", .{});
    try out_writer.print("// {} Functions\n", .{functions_array.items.len});
    try out_writer.print("//\n", .{});
    for (functions_array.items) |function_node| {
        try generateFunction(sdk_file, out_writer, function_node.Object);
    }
    std.debug.assert(functions_array.items.len == sdk_file.func_exports.count());
    try out_writer.print("\n", .{});
    try out_writer.print("//\n", .{});
    try out_writer.print("// {} Unicode Aliases\n", .{unicode_aliases.items.len});
    try out_writer.print("//\n", .{});
    for (unicode_aliases.items) |unicode_alias_node| {
        //try generateUnicodeName(sdk_file, out_writer, unicode_alias_node.Object);
    }
    // TODO: uncomment this when I start generating aliases
    //std.debug.assert(unicode_aliases.items.len == sdk_file.unicode_aliases.count());

    const import_total = @boolToInt(sdk_file.uses_guid) + sdk_file.top_level_api_imports.count();
    try out_writer.print("\n", .{});
    try out_writer.print("//\n", .{});
    try out_writer.print("// {} Imports\n", .{import_total});
    try out_writer.print("//\n", .{});
    if (sdk_file.uses_guid) {
        try out_writer.writeAll("const Guid = @import(\"../zig.zig\").Guid;\n");
    }
    {
        var it = sdk_file.top_level_api_imports.iterator();
        while (it.next()) |import| {
            const name = import.key;
            const api = import.value;
            try out_writer.print("const {s} = u32; // TODO: import from {s}\n", .{name, api});
        }
    }

    try out_writer.print(
        \\
        \\test "" {{
        \\    const constant_export_count = {};
        \\    const type_export_count = {};
        \\    const func_export_count = {};
        \\    const unicode_alias_count = {};
        \\    const import_count = {};
        \\    @setEvalBranchQuota(
        \\        constant_export_count +
        \\        type_export_count +
        \\        func_export_count +
        \\        unicode_alias_count +
        \\        import_count +
        \\        2 // TODO: why do I need these extra 2?
        \\    );
        \\    @import("std").testing.refAllDecls(@This());
        \\}}
        \\
    , .{sdk_file.const_exports.items.len,
        sdk_file.type_exports.count(),
        sdk_file.func_exports.count(),
        0, // TODO: uncomment when I start generating these: unicode_aliases.items.len,
        import_total,
    });
}

fn typeIsVoid(type_obj: json.ObjectMap, sdk_file: *SdkFile) !bool {
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).String;
    if (std.mem.eql(u8, kind, "Native")) {
        const Name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).String;
        return std.mem.eql(u8, name, "void");
    }
    return false;
}

// convenient function that combines both adding type refs and creating a formatter
// for the type.   These 2 operations are orthogonal, however, combining them helps ensure
// that generating a type reference is not done without also adding that reference to the api
// being generated.
fn addTypeRefs(sdk_file: *SdkFile, type_ref: json.ObjectMap) anyerror!TypeRefFormatter {
    try addTypeRefsNoFormatter(sdk_file, type_ref);
    return formatTypeRef(type_ref, .top_level, sdk_file);
}

fn addTypeRefsNoFormatter(sdk_file: *SdkFile, type_ref: json.ObjectMap) anyerror!void {
    const kind = (try jsonObjGetRequired(type_ref, "Kind", sdk_file)).String;
    if (std.mem.eql(u8, kind, "Native")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Name"}, sdk_file);
        const name = (try jsonObjGetRequired(type_ref, "Name", sdk_file)).String;
        if (std.mem.eql(u8, name, "Void")) {
            // void is special
        } else if (std.mem.eql(u8, name, "Guid")) {
            sdk_file.uses_guid = true;
        } else if (global_native_type_map.get(name) == null) {
            std.debug.panic("unknown Native type '{s}'", .{name});
        }
    } else if (std.mem.eql(u8, kind, "ApiRef")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Name", "Api", "Parents"}, sdk_file);
        const tmp_name = (try jsonObjGetRequired(type_ref, "Name", sdk_file)).String;
        const api = (try jsonObjGetRequired(type_ref, "Api", sdk_file)).String;
        const parents = (try jsonObjGetRequired(type_ref, "Parents", sdk_file)).Array;
        try sdk_file.addApiImport(tmp_name, api, parents);
    } else if (std.mem.eql(u8, kind, "PointerTo")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Child"}, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).Object);
    } else if (std.mem.eql(u8, kind, "Array")) {
        try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"Kind", "Child"}, sdk_file);
        try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "Child", sdk_file)).Object);
    } else {
        std.debug.print("kind is '{s}'\n", .{kind});
        const is_arrayptr = std.mem.eql(u8, kind, "arrayptr");
        if (is_arrayptr or std.mem.eql(u8, kind, "singleptr")) {
            try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"kind", "const", "subtype"}, sdk_file);
            try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "subtype", sdk_file)).Object);
        } else if (std.mem.eql(u8, kind, "funcptr")) {
            try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"kind", "return_type", "args"}, sdk_file);
            try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "return_type", sdk_file)).Object);
            for ((try jsonObjGetRequired(type_ref, "args", sdk_file)).Array.items) |arg_node| {
                const arg_obj = arg_node.Object;
                try jsonObjEnforceKnownFieldsOnly(arg_obj, &[_][]const u8 {"type", "name"}, sdk_file);
                try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(arg_obj, "type", sdk_file)).Object);
            }
        } else {
            std.debug.assert(std.mem.eql(u8, kind, "fixedlenarray"));
            try jsonObjEnforceKnownFieldsOnly(type_ref, &[_][]const u8 {"kind", "len", "subtype"}, sdk_file);
            try addTypeRefsNoFormatter(sdk_file, (try jsonObjGetRequired(type_ref, "subtype", sdk_file)).Object);
        }
    }
}


fn fmtConstAssign(native_type: NativeType, value: json.Value) ConstValueFormatter {
    return .{ .native_type = native_type, .value = value };
}
const ConstValueFormatter = struct {
    native_type: NativeType,
    value: json.Value,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) std.os.WriteError!void {
        if (self.native_type == .String) {
            try writer.print("= {}", .{fmtJson(self.value)});
            return;
        }
        const zig_type = nativeTypeToZigType(self.native_type);
        if (self.native_type == .Single or self.native_type == .Double) {
            switch (self.value) {
                .String => |float_str| {
                    if (std.mem.eql(u8, float_str, "inf")) {
                        try writer.print("= @import(\"std\").math.inf({s})", .{zig_type});
                        return;
                    } else if (std.mem.eql(u8, float_str, "-inf")) {
                        try writer.print("= -@import(\"std\").math.inf({s})", .{zig_type});
                        return;
                    } else if (std.mem.eql(u8, float_str, "nan")) {
                        try writer.print("= @import(\"std\").math.nan({s})", .{zig_type});
                        return;
                    } else {
                        std.debug.panic("unexpected float string value '{s}'", .{float_str});
                    }
                    return;
                },
                else => {},
            }
        }
        try writer.print(": {s} = {}", .{zig_type, fmtJson(self.value)});
    }
};



const DepthContext = enum {top_level, child};
const TypeRefFormatter = struct {
    type_ref: json.ObjectMap,
    // we need to know if the type is the top-level type or a child type of something like a pointer
    // so we can generate the correct `void` type.  Top level void types become void, but pointers
    // to void types must become pointers to the `opaque{}` type.
    depth_context: DepthContext,
    sdk_file: *SdkFile,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) std.os.WriteError!void {
        const kind = (jsonObjGetRequired(self.type_ref, "Kind", self.sdk_file) catch unreachable).String;
        if (std.mem.eql(u8, kind, "Native")) {
            jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Name"}, self.sdk_file) catch unreachable;
            const name = (jsonObjGetRequired(self.type_ref, "Name", self.sdk_file) catch unreachable).String;
            if (std.mem.eql(u8, name, "Void")) {
                try writer.writeAll(if (self.depth_context == .child) "opaque{}" else "void");
            } else if (std.mem.eql(u8, name, "Guid")) {
                try writer.writeAll("Guid");
            } else {
                const native_type = global_native_type_map.get(name) orelse std.debug.panic("unknown Native type '{0}'", .{name});
                try writer.writeAll(nativeTypeToZigType(native_type));
            }
        } else if (std.mem.eql(u8, kind, "ApiRef")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Name", "Api", "Parents"}, self.sdk_file);
            const name = (try jsonObjGetRequired(self.type_ref, "Name", self.sdk_file)).String;
            const parents = (try jsonObjGetRequired(self.type_ref, "Parents", self.sdk_file)).Array;
            for (parents.items) |parent| {
                try writer.writeAll(parent.String);
                try writer.writeAll(".");
            }
            try writer.writeAll(name);
        } else if (std.mem.eql(u8, kind, "alias")) {
            jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"kind", "name"}, self.sdk_file) catch unreachable;
            try writer.writeAll((jsonObjGetRequired(self.type_ref, "name", self.sdk_file) catch unreachable).String);
        } else if (std.mem.eql(u8, kind, "PointerTo")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Child"}, self.sdk_file);
            const child = (try jsonObjGetRequired(self.type_ref, "Child", self.sdk_file)).Object;
            try writer.writeAll("*");
            try formatTypeRef(child, .child, self.sdk_file).format(fmt, options, writer);
        } else if (std.mem.eql(u8, kind, "Array")) {
            try jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"Kind", "Child"}, self.sdk_file);
            const child = (try jsonObjGetRequired(self.type_ref, "Child", self.sdk_file)).Object;
            // TODO: get the actual size!!
            try writer.writeAll("[1]");
            try formatTypeRef(child, .child, self.sdk_file).format(fmt, options, writer);
        } else {
            std.debug.print("[DEBUG] Kind '{s}'\n", .{kind});
            const is_arrayptr = std.mem.eql(u8, kind, "arrayptr");
            if (is_arrayptr or std.mem.eql(u8, kind, "singleptr")) {
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // TODO: need to know if this is a sentinal terminated pointer
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                // !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"kind", "const", "subtype"}, self.sdk_file) catch unreachable;
                const is_const = (jsonObjGetRequired(self.type_ref, "const", self.sdk_file) catch unreachable).Bool;
                const subtype = (jsonObjGetRequired(self.type_ref, "subtype", self.sdk_file) catch unreachable).Object;
                try writer.writeAll(if (is_arrayptr) "?[*]" else "?*");
                if (is_const) {
                    try writer.writeAll("const ");
                }
                try formatTypeRef(subtype, .child, self.sdk_file).format(fmt, options, writer);
            } else if (std.mem.eql(u8, kind, "funcptr")) {
                jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"kind", "return_type", "args"}, self.sdk_file) catch unreachable;
                try writer.writeAll("fn(");
                var arg_prefix : []const u8 = "";
                for ((jsonObjGetRequired(self.type_ref, "args", self.sdk_file) catch unreachable).Array.items) |arg_node| {
                    const arg_obj = arg_node.Object;
                    jsonObjEnforceKnownFieldsOnly(arg_obj, &[_][]const u8 {"name", "type"}, self.sdk_file) catch unreachable;
                    const arg_name = (jsonObjGetRequired(arg_obj, "name", self.sdk_file) catch unreachable).String;
                    const arg_type = (jsonObjGetRequired(arg_obj, "type", self.sdk_file) catch unreachable).Object;
                    try writer.print("{s}{s}: ", .{arg_prefix, arg_name});
                    try formatTypeRef(arg_type, .top_level, self.sdk_file).format(fmt, options, writer);
                    arg_prefix = ", ";
                }
                try writer.writeAll(") callconv(.Stdcall) ");
                const return_type = (jsonObjGetRequired(self.type_ref, "return_type", self.sdk_file) catch unreachable).Object;
                try formatTypeRef(return_type, .top_level, self.sdk_file).format(fmt, options, writer);
            } else {
                std.debug.assert(std.mem.eql(u8, kind, "fixedlenarray"));
                jsonObjEnforceKnownFieldsOnly(self.type_ref, &[_][]const u8 {"kind", "len", "subtype"}, self.sdk_file) catch unreachable;
                const len = (jsonObjGetRequired(self.type_ref, "len", self.sdk_file) catch unreachable).Integer;
                const subtype = (jsonObjGetRequired(self.type_ref, "subtype", self.sdk_file) catch unreachable).Object;
                try writer.print("[{}]", .{len});
                try formatTypeRef(subtype, .child, self.sdk_file).format(fmt, options, writer);
            }
        }
    }
};
pub fn formatTypeRef(type_ref: json.ObjectMap, depth_context: DepthContext, sdk_file: *SdkFile) TypeRefFormatter {
    return .{ .type_ref = type_ref, .depth_context = depth_context, .sdk_file = sdk_file };
}

fn generateConstant(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, constant_obj: json.ObjectMap) !void {
    try jsonObjEnforceKnownFieldsOnly(constant_obj, &[_][]const u8 {"Name", "NativeType", "Value","Attrs"}, sdk_file);
    const name_tmp = (try jsonObjGetRequired(constant_obj, "Name", sdk_file)).String;
    const native_type_str = (try jsonObjGetRequired(constant_obj, "NativeType", sdk_file)).String;
    const value_node = try jsonObjGetRequired(constant_obj, "Value", sdk_file);

    // TODO: handle Attrs
    const attrs_node = (try jsonObjGetRequired(constant_obj, "Attrs", sdk_file)).Array;

    const name_pool = try global_symbol_pool.add(name_tmp);
    try sdk_file.const_exports.append(name_pool);

    const native_type = global_native_type_map.get(native_type_str) orelse {
        std.log.err("constant '{s}' has an unknown NativeType '{s}'\n", .{name_pool, native_type_str});
        return error.AlreadyReported;
    };

    try out_writer.print("pub const {s} {};\n", .{name_pool, fmtConstAssign(native_type, value_node)});
}

fn generateType(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, type_obj: json.ObjectMap) !void {
    const kind = (try jsonObjGetRequired(type_obj, "Kind", sdk_file)).String;
    const tmp_name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).String;
    //const type_entry = try getTypeWithTempString(tmp_name);
    //if (type_entry.metadata.builtin) {
    //    std.debug.warn("Error: type '{s}' is defined and builtin?\n", .{tmp_name});
    //    return error.AlreadyReported;
    //}
    //std.debug.assert(std.mem.eql(u8, tmp_name, type_entry.zig_type_from_pool));
    const pool_name = try global_symbol_pool.add(tmp_name);

    std.debug.assert(sdk_file.type_exports.get(pool_name) == null);
    try sdk_file.type_exports.put(pool_name, .{});

    if (std.mem.eql(u8, kind, "NativeTypedef")) {
        try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Name", "Kind", "Def"}, sdk_file);
        const def_type = (try jsonObjGetRequired(type_obj, "Def", sdk_file)).Object;
        const zig_type_formatter = try addTypeRefs(sdk_file, def_type);
        try out_writer.print("pub const {s} = {};\n", .{tmp_name, zig_type_formatter});
    } else if (std.mem.eql(u8, kind, "Enum")) {
        try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Name", "Kind", "Values"}, sdk_file);
        const values = (try jsonObjGetRequired(type_obj, "Values", sdk_file)).Array;
        try out_writer.print("pub const {s} = extern enum(i64) {{ // TODO: get actual base type\n", .{tmp_name});
        if (values.items.len == 0) {
            // zig doesn't allow empty enums
            try out_writer.print("    _\n", .{});
        } else for (values.items) |value_node| {
            const value_obj = value_node.Object;
            try jsonObjEnforceKnownFieldsOnly(value_obj, &[_][]const u8 {"Name", "Value"}, sdk_file);
            const value_tmp_name = (try jsonObjGetRequired(value_obj, "Name", sdk_file)).String;
            const value_literal = try jsonObjGetRequired(value_obj, "Value", sdk_file);
            try out_writer.print("    {s} = {},\n", .{value_tmp_name, fmtJson(value_literal)});
            // TODO: should we generate a "_" field?  How do we know whether these enums are exhaustive?
        }
        try out_writer.print("}};\n", .{});
    } else if (std.mem.eql(u8, kind, "Struct")) {
        try jsonObjEnforceKnownFieldsOnly(type_obj, &[_][]const u8 {"Kind", "Name", "Size", "PackingSize", "Fields", "Comment", "NestedTypes"}, sdk_file);
        const struct_name = (try jsonObjGetRequired(type_obj, "Name", sdk_file)).String;
        const struct_size = (try jsonObjGetRequired(type_obj, "Size", sdk_file)).Integer;
        const struct_packing_size = (try jsonObjGetRequired(type_obj, "PackingSize", sdk_file)).Integer;
        const struct_fields = (try jsonObjGetRequired(type_obj, "Fields", sdk_file)).Array;
        const struct_nested_types = (try jsonObjGetRequired(type_obj, "NestedTypes", sdk_file)).Array;
        if (struct_fields.items.len == 0) {
            // TODO: handle nested types
            try out_writer.print("pub const {s} = opaque{{}}; // an empty struct?\n", .{struct_name});
        } else {
            try out_writer.print("pub const {s} = extern struct {{\n", .{struct_name});
            for (struct_fields.items) |field_node| {
                const field_obj = field_node.Object;
                try jsonObjEnforceKnownFieldsOnly(field_obj, &[_][]const u8 {"Name", "Type"}, sdk_file);
                const field_name = (try jsonObjGetRequired(field_obj, "Name", sdk_file)).String;
                const field_type = (try jsonObjGetRequired(field_obj, "Type", sdk_file)).Object;
                const field_type_formatter = try addTypeRefs(sdk_file, field_type);
                try out_writer.print("    {}: {},\n", .{std.zig.fmtId(field_name), field_type_formatter});
            }
            for (struct_nested_types.items) |nested_type_node| {
                const nested_type_obj = nested_type_node.Object;
                const nested_type_name = (try jsonObjGetRequired(nested_type_obj, "Name", sdk_file)).String;
                try out_writer.print("    const {s} = u32; // TODO: generate this nested type!\n", .{nested_type_name});
            }
            try out_writer.print("}};\n", .{});
        }
    } else {
        if (dhcp_type_conflicts.get(tmp_name)) |_| {
            try out_writer.print("// TODO: this dhcp type has been removed because it conflicts with a nested type '{s}'\n", .{tmp_name});
            return;
        }

        try out_writer.print("pub const {s} = u32; // unhandled Kind '{s}'\n", .{tmp_name, kind});
        //std.debug.warn("{s}: Error: unknown type kind '{s}'", .{sdk_file.name, kind});
        //return error.AlreadyReported;
    }
}

// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// TODO: remove this when I figure out how to deal with these conflicts
//       they are top-level symbols that conflict with nested type names,
//       Zig doesn't seem to allow a nested type to shadow/overwrite a top-level type
// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
const dhcp_type_conflicts = std.ComptimeStringMap(Nothing, .{
        .{ "DHCP_SUBNET_ELEMENT_UNION", .{} },
        .{ "DHCP_OPTION_ELEMENT_UNION", .{} },
        .{ "DHCP_OPTION_SCOPE_UNION6", .{} },
        .{ "DHCP_CLIENT_SEARCH_UNION", .{} },
        .{ "DHCP_SUBNET_ELEMENT_UNION_V4", .{} },
        .{ "DHCP_SUBNET_ELEMENT_UNION_V6", .{} },
});

fn generateFunction(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, function_obj: json.ObjectMap) !void {
    try jsonObjEnforceKnownFieldsOnly(function_obj, &[_][]const u8 {"Name", "SetLastError", "DllImport", "ReturnType", "Params"}, sdk_file);
    const func_name_tmp = (try jsonObjGetRequired(function_obj, "Name", sdk_file)).String;
    const set_last_error = (try jsonObjGetRequired(function_obj, "SetLastError", sdk_file)).Bool;
    const dll_import = (try jsonObjGetRequired(function_obj, "DllImport", sdk_file)).String;
    const return_type = (try jsonObjGetRequired(function_obj, "ReturnType", sdk_file)).Object;
    const params = (try jsonObjGetRequired(function_obj, "Params", sdk_file)).Array;

    const func_name_pool = try global_symbol_pool.add(func_name_tmp);
    try sdk_file.func_exports.put(func_name_pool, .{});

    try out_writer.print("pub extern \"{s}\" fn {s}(\n", .{dll_import, func_name_pool});
    for (params.items) |param_node| {
        const param_obj = param_node.Object;
        try jsonObjEnforceKnownFieldsOnly(param_obj, &[_][]const u8 {"Name", "Type"}, sdk_file);
        const param_name = (try jsonObjGetRequired(param_obj, "Name", sdk_file)).String;
        const param_type = (try jsonObjGetRequired(param_obj, "Type", sdk_file)).Object;
        //const param_type_formatter = try addTypeRefs(sdk_file, param_type);
        try out_writer.print("    {s}: u32, // TODO: param type {},\n", .{std.zig.fmtId(param_name), fmtJson(param_type)});
    }
    //const return_type_formatter = try addTypeRefs(sdk_file, return_type);
    try out_writer.print(") callconv(@import(\"std\").os.windows.WINAPI) u32; // TODO: return type {}\n", .{fmtJson(return_type)});
}

fn getPoolStringWithParts(a: *std.mem.Allocator, slices: []const []const u8) ![]const u8 {
    const tmp = try std.mem.concat(a, u8, slices);
    defer a.free(tmp);
    return try global_symbol_pool.add(tmp);
}

fn generateUnicodeName(sdk_file: *SdkFile, out_writer: std.fs.File.Writer, unicode_name_obj: json.ObjectMap) !void {
    try jsonObjEnforceKnownFieldsOnly(unicode_name_obj, &[_][]const u8 {"name"}, sdk_file);
    const name_tmp = (try jsonObjGetRequired(unicode_name_obj, "name", sdk_file)).String;

    const name_ansi_pool = try getPoolStringWithParts(allocator, &[_][]const u8 {name_tmp, "A"});
    const name_unicode_pool = try getPoolStringWithParts(allocator, &[_][]const u8 {name_tmp, "W"});

    const NameKind = enum { none, type, func };
    const ansi_kind : NameKind = init: {
        if (sdk_file.type_exports.get(name_ansi_pool)) |_| break :init .type;
        if (sdk_file.func_exports.get(name_ansi_pool)) |_| break :init .func;
        break :init .none;
    };
    const unicode_kind : NameKind = init: {
        if (sdk_file.type_exports.get(name_unicode_pool)) |_| break :init .type;
        if (sdk_file.func_exports.get(name_unicode_pool)) |_| break :init .func;
        break :init .none;
    };
    if (ansi_kind == .none and unicode_kind == .none) {
        std.debug.warn("Error: unicode name '{s}' does not have a corresponding Ansi or Unicode name ({s} or {s})\n", .{name_tmp, name_ansi_pool, name_unicode_pool});
        return error.AlreadyReported;
    }
    if (ansi_kind != .none and unicode_kind != .none and ansi_kind != unicode_kind) {
        std.debug.warn("Error: ansi name '{s}' is a {} but the unicode name '{s}' is a {}\n", .{name_ansi_pool, ansi_kind, name_unicode_pool, unicode_kind});
        return error.AlreadyReported;
    }

    const name_pool = try global_symbol_pool.add(name_tmp);
    const common_kind = if (ansi_kind != .none) ansi_kind else unicode_kind;
    switch (common_kind) {
        .none => unreachable,
        .type => try sdk_file.type_exports.put(name_pool, try getTypeWithPoolString(name_pool)),
        .func => try sdk_file.func_exports.put(name_pool, .{}),
    }

    // TODO: would it be better to generate code that checks the unicode mode once for all symbols?
    try out_writer.print("pub const {s} = switch (@import(\"../zig.zig\").unicode_mode) {{\n", .{name_pool});
    if (ansi_kind == .none) {
        try out_writer.print("    .ansi    => @compileError(\"'{s}' does not exist\"),\n", .{name_ansi_pool});
    } else {
        try out_writer.print("    .ansi    => {s},\n", .{name_ansi_pool});
    }
    if (unicode_kind == .none) {
        try out_writer.print("    .unicode => @compileError(\"'{s}' does not exist\"),\n", .{name_unicode_pool});
    } else {
        try out_writer.print("    .unicode => {s},\n", .{name_unicode_pool});
    }
    try out_writer.print("    .unspecified => if (@import(\"builtin\").is_test) opaque{{}} else @compileError(\"Cannot call '{s}' because the root module has not set UNICODE to true or false.\"),\n", .{name_pool});
    try out_writer.print("}};\n", .{});
}

//const FixIntegerLiteralFormatter = struct {
//    literal: []const u8,
//    is_c_int: bool,
//    pub fn format(
//        self: @This(),
//        comptime fmt: []const u8,
//        options: std.fmt.FormatOptions,
//        writer: anytype,
//    ) !void {
//        var literal = self.literal;
//        if (std.mem.endsWith(u8, literal, "UL") or std.mem.endsWith(u8, literal, "ul")) {
//            literal = literal[0..literal.len - 2];
//        } else if (std.mem.endsWith(u8, literal, "L") or std.mem.endsWith(u8, literal, "U")) {
//            literal = literal[0..literal.len - 1];
//        }
//        var radix : u8 = 10;
//        if (std.mem.startsWith(u8, literal, "0x")) {
//            literal = literal[2..];
//            radix = 16;
//        } else if (std.mem.startsWith(u8, literal, "0X")) {
//            std.debug.warn("[WARNING] found integer literal that begins with '0X' instead of '0x': '{s}' (should probably file an issue)\n", .{self.literal});
//            literal = literal[2..];
//            radix = 16;
//        }
//
//        var literal_buf: [30]u8 = undefined;
//        if (self.is_c_int) {
//            // we have to parse the integer literal and convert it to a negative since Zig
//            // doesn't allow casting largs positive integer literals to c_int if they overflow 31 bits
//            const value = std.fmt.parseInt(i64, literal, radix) catch @panic("failed to parse integer literal (TODO: print better error)");
//            std.debug.assert(value >= 0); // negative not implemented, haven't found any yet
//            if (value > std.math.maxInt(c_int)) {
//                // TODO: print better error message if this fails
//                std.debug.assert(value <= std.math.maxInt(c_uint));
//                literal_buf[0] = '-';
//                literal = literal_buf[0..1 + std.fmt.formatIntBuf(literal_buf[1..],
//                    @as(i64, std.math.maxInt(c_uint)) + 1 - value, 10, false, .{})];
//                radix = 10;
//            }
//        }
//
//        const prefix : []const u8 = if (radix == 16) "0x" else "";
//        try writer.print("{s}{s}", .{prefix, literal});
//    }
//};
//pub fn fixIntegerLiteral(literal: []const u8, is_c_int: bool) FixIntegerLiteralFormatter {
//    return .{ .literal = literal, .is_c_int = is_c_int };
//}

//const CToZigPtrFormatter = struct {
//    type_name_from_pool: []const u8,
//    pub fn format(
//        self: @This(),
//        comptime fmt: []const u8,
//        options: std.fmt.FormatOptions,
//        writer: anytype,
//    ) !void {
//        if (self.type_name_from_pool.ptr == global_void_type_from_pool_ptr) {
//            try writer.writeAll("*c_void");
//        } else {
//            // TODO: would be nice if we could use either *T or [*]T zig pointer semantics
//            try writer.print("[*c]{s}", .{self.type_name_from_pool});
//        }
//    }
//};
//pub fn formatCToZigPtr(type_name_from_pool: []const u8) CToZigPtrFormatter {
//    return .{ .type_name_from_pool = type_name_from_pool };
//}

pub fn SliceFormatter(comptime T: type, comptime spec: []const u8) type { return struct {
    slice: []const T,
    pub fn format(
        self: @This(),
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        var first : bool = true;
        for (self.slice) |e| {
            if (first) {
                first = false;
            } else {
                try writer.writeAll(", ");
            }
            try std.fmt.format(writer, "{" ++ spec ++ "}", .{e});
        }
    }
};}
pub fn formatSliceT(comptime T: type, comptime spec: []const u8, slice: []const T) SliceFormatter(T, spec) {
    return .{ .slice = slice };
}
// TODO: implement this
//pub fn formatSlice(slice: anytype) SliceFormatter(T) {
//    return .{ .slice = slice };
//}

fn jsonPanic() noreturn {
    @panic("an assumption about the json format was violated");
}
fn jsonPanicMsg(comptime msg: []const u8, args: anytype) noreturn {
    std.debug.panic("an assumption about the json format was violated: " ++ msg, args);
}

fn jsonEnforce(cond: bool) void {
    if (!cond) {
        jsonPanic();
    }
}
fn jsonEnforceMsg(cond: bool, comptime msg: []const u8, args: anytype) void {
    if (!cond) {
        jsonPanicMsg(msg, args);
    }
}

fn jsonObjEnforceKnownFieldsOnly(map: json.ObjectMap, known_fields: []const []const u8, file_thing: anytype) !void {
    if (@TypeOf(file_thing) == *SdkFile)
        return jsonObjEnforceKnownFieldsOnlyImpl(map, known_fields, file_thing.json_basename2);
    if (@TypeOf(file_thing) == []const u8)
        return jsonObjEnforceKnownFieldsOnlyImpl(map, known_fields, file_thing);
    @compileError("unhandled file_thing type: " ++ @typeName(@TypeOf(file_thing)));
}

fn jsonObjEnforceKnownFieldsOnlyImpl(map: json.ObjectMap, known_fields: []const []const u8, file_for_error: []const u8) !void {
    var it = map.iterator();
    fieldLoop: while (it.next()) |kv| {
        for (known_fields) |known_field| {
            if (std.mem.eql(u8, known_field, kv.key))
                continue :fieldLoop;
        }
        std.debug.warn("{s}: Error: JSON object has unknown field '{s}', expected one of: {}\n", .{file_for_error, kv.key, formatSliceT([]const u8, "s", known_fields)});
        jsonPanic();
    }
}

fn jsonObjGetRequired(map: json.ObjectMap, field: []const u8, file_thing: anytype) !json.Value {
    if (@TypeOf(file_thing) == *SdkFile)
        return jsonObjGetRequiredImpl(map, field, file_thing.json_basename2);
    if (@TypeOf(file_thing) == []const u8)
        return jsonObjGetRequiredImpl(map, field, file_thing);
    @compileError("unhandled file_thing type: " ++ @typeName(@TypeOf(file_thing)));
}
fn jsonObjGetRequiredImpl(map: json.ObjectMap, field: []const u8, file_for_error: []const u8) !json.Value {
    return map.get(field) orelse {
        // TODO: print file location?
        std.debug.warn("{s}: json object is missing '{s}' field: {}\n", .{file_for_error, field, fmtJson(map)});
        jsonPanic();
    };
}

const JsonFormatter = struct {
    value: json.Value,
    pub fn format(
        self: JsonFormatter,
        comptime fmt: []const u8,
        options: std.fmt.FormatOptions,
        writer: anytype,
    ) !void {
        try std.json.stringify(self.value, .{}, writer);
    }
};
pub fn fmtJson(value: anytype) JsonFormatter {
    if (@TypeOf(value) == json.ObjectMap) {
        return .{ .value = .{ .Object = value } };
    }
    if (@TypeOf(value) == json.Array) {
        return .{ .value = .{ .Array = value } };
    }
    if (@TypeOf(value) == []json.Value) {
        return .{ .value = .{ .Array = json.Array  { .items = value, .capacity = value.len, .allocator = undefined } } };
    }
    return .{ .value = value };
}

fn cleanDir(dir: std.fs.Dir, sub_path: []const u8) !void {
    try dir.deleteTree(sub_path);
    const MAX_ATTEMPTS = 30;
    var attempt : u32 = 1;
    while (true) : (attempt += 1) {
        if (attempt > MAX_ATTEMPTS) {
            std.debug.warn("Error: failed to delete '{s}' after {} attempts\n", .{sub_path, MAX_ATTEMPTS});
            return error.AlreadyReported;
        }
        // ERROR: windows.OpenFile is not handling error.Unexpected NTSTATUS=0xc0000056
        dir.makeDir(sub_path) catch |e| switch (e) {
            else => {
                std.debug.warn("[DEBUG] makedir failed with {}\n", .{e});
                //return error.AlreadyReported;
                continue;
            },
        };
        break;
    }

}

fn getcwd(a: *std.mem.Allocator) ![]u8 {
    var path_buf : [std.fs.MAX_PATH_BYTES]u8 = undefined;
    const path = try std.os.getcwd(&path_buf);
    const path_allocated = try a.alloc(u8, path.len);
    std.mem.copy(u8, path_allocated, path);
    return path_allocated;
}

// TODO: should this be in std lib?
fn camelToSnake(a: *std.mem.Allocator, camel: []const u8) ![]const u8 {
    std.debug.assert(camel.len >= 0); // code assumes this right now

    var new_len = camel.len;
    {var i : usize = 1; while (i < camel.len) : (i += 1) {
        if (std.ascii.isUpper(camel[i]) and std.ascii.isLower(camel[i-1])) {
            new_len += 1;
        }
    }}

    var snake = try a.alloc(u8, new_len);
    errdefer a.free(snake);

    snake[0] = camel[0] + (if (std.ascii.isUpper(camel[0])) @as(u8, 'a'-'A') else 0);

    var snake_index : usize = 1;
    {var i: usize = 1; while (i < camel.len) : (i += 1) {
        const is_upper = std.ascii.isUpper(camel[i]);
        if (is_upper and std.ascii.isLower(camel[i-1])) {
            snake[snake_index] = '_';
            snake_index += 1;
        }
        snake[snake_index] = camel[i] + (if (is_upper) @as(u8, 'a'-'A') else 0);
        snake_index += 1;
    }}
    std.debug.assert(snake_index == new_len);
    return snake;
}
